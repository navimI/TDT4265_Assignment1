{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an outline for your report to ease the amount of work required to create your report. Jupyter notebook supports markdown, and I recommend you to check out this [cheat sheet](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet). If you are not familiar with markdown.\n",
    "\n",
    "Before delivery, **remember to convert this file to PDF**. You can do it in two ways:\n",
    "1. Print the webpage (ctrl+P or cmd+P)\n",
    "2. Export with latex. This is somewhat more difficult, but you'll get somehwat of a \"prettier\" PDF. Go to File -> Download as -> PDF via LaTeX. You might have to install nbconvert and pandoc through conda; `conda install nbconvert pandoc`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## task 1a)\n",
    "\n",
    "The intersection over Union(IoU) is the measurement of the ratio between the predicted and the ground truth bounding boxes. The measurement is considered true positive if the result is overlaped by 50%. This evaluation is used in object detection task to measure the similarity between the predicted bounding boxes and the ground true bounding boxes.\n",
    "\n",
    "To calculate the IoU we have to calcualte the area of the intersection between the two bounding boxex, calculate the union between the two bounding boxes, and calculate the ratio between them.\n",
    "\n",
    "IoU = $\\frac{area(Bp \\cap Bgt)}{area(Bp \\cup Bgt)}$\n",
    "\n",
    "where $Bp$ is the predicted bounding box and $Bgt$ is the ground truth bounding box.\n",
    "\n",
    "![IoU](IoU.jpeg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## task 1b)\n",
    "\n",
    "Precision measures how accurate is your predictions. i.e. the percentage of your predictions are correct.\n",
    "\n",
    "\n",
    "\n",
    "Recall measures how good you find all the positives. For example, we can find 80% of the possible positive cases in our top K predictions.\n",
    "\n",
    "The precision and recall can be expressed mathematically as follows:\n",
    "\n",
    "Precision = $\\frac{TP}{TP + FP}$\n",
    "\n",
    "Recall = $\\frac{TP}{TP + FN}$\n",
    "\n",
    "where $TP$ (true positive) is the number of correct positive predictions, $FP$ (false positive) is the number of incorrect positive predictions, and $FN$ (false negative) is the number of incorrect negative predictions.\n",
    "\n",
    "A true positive is a prediction that is correctly classified as positive, meaning that it belongs to the positive class and the model correctly identifies it as such. A false positive, on the other hand, is a prediction that is incorrectly classified as positive, meaning that it does not actually belong to the positive class but the model identifies it as such.\n",
    "\n",
    "## task 1c)\n",
    "\n",
    "Precision values for class 1 at different recall levels:\n",
    "\n",
    "Recall = 0.0: Precision = 1.0  \n",
    "Recall = 0.1: Precision = 1.0  \n",
    "Recall = 0.2: Precision = 1.0  \n",
    "Recall = 0.3: Precision = 1.0  \n",
    "Recall = 0.4: Precision = 1.0  \n",
    "Recall = 0.5: Precision = 1.0  \n",
    "Recall = 0.6: Precision = 1.0  \n",
    "Recall = 0.7: Precision = 0.5  \n",
    "Recall = 0.8 :Precision = 0.5  \n",
    "Recall = 0.9 :Precision = 0.5  \n",
    "Recall = 0.10 :Precision= 0.2  \n",
    "\n",
    "Area under the curve for class 1 AP = $\\frac{( 7 * 1 +3 * 0.5 + 0.2)}{11} $\n",
    "The solution is $AP = 0.7909$\n",
    "\n",
    "Precision values for class 2 at different recall levels:\n",
    "\n",
    "Recall = 0.0: Precision = 1.0  \n",
    "Recall = 0.1: Precision = 1.0  \n",
    "Recall = 0.2: Precision = 1.0  \n",
    "Recall = 0.3: Precision = 1.0  \n",
    "Recall = 0.4: Precision = 0.8  \n",
    "Recall = 0.5: Precision = 0.6  \n",
    "Recall = 0.6: Precision = 0.6  \n",
    "Recall = 0.7: Precision = 0.5  \n",
    "Recall = 0.8: Precision = 0.5  \n",
    "Recall = 0.9: Precision = 0.5  \n",
    "Recall = 1.0: Precision = 0.2\n",
    "\n",
    "Area under the curve for class  $AP = \\frac{( 4 * 1 + 0.8 + 2 * 0.6 + 3 * 0.5 + 0.2)}{11} $\n",
    "The solution is $AP = 0.7$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2\n",
    "\n",
    "### Task 2f)\n",
    "![task 2f](task2/task2f.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3a)\n",
    "The filtering operation to remove overlapping boxes in object detection with SSD (Single Shot Multibox Detector) is called Non-maximum Suppression (NMS). NMS is a post-processing technique commonly used in object detection to eliminate duplicate detections and improve the overall detection accuracy. It works by suppressing the boxes that have a high degree of overlap (measured using Intersection over Union) and keeping only the boxes with the highest confidence scores.\n",
    "\n",
    "### Task 3b)\n",
    "The statement is false. Predictions from the shallower layers in SSD are responsible for detecting small objects. Shallow layers can be used to predict small objects because small objects donâ€™t need bigger receptive fields.\n",
    "\n",
    "### Task 3c)\n",
    "This is used to be able to detect objects with different shapes and aspect ratios. For example, if we want to detect a car, we can use a square anchor box. However, if we want to detect a person, we can use a rectangular anchor box. This is because a person is not always in a square shape.\n",
    "\n",
    "### Task 3d)\n",
    "One of the main differences between SSD and YOLOv1/v2 that SSD is more accurate than YOLOv1/v2. SSD is more accurate because it uses a multi-scale feature map, which allows it to detect objects at different scales. YOLOv1/v2, on the other hand, uses a single-scale feature map, which means that it can only detect objects at one scale.\n",
    "\n",
    "### Task 3e)\n",
    "The total number of anchor boxes for this feature map, we can multiply the number of locations on the feature map (38x38) by the number of anchors per location (6). This gives us a total of 38 x 38 x 6 = 8664 anchor boxes for this feature map.\n",
    "\n",
    "### Task 3f)\n",
    "The total number of anchor boxes for the entire network, we can sum up the number of anchor boxes for each feature map. This gives us (38 x 38 + 19 x 19 + 10 x 10 + 5 x 5 + 3 x 3 +1 x1) x6 = 34956 anchor boxes in total for the entire network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4b)\n",
    "\n",
    "![task 4b](task4b.png)\n",
    "mAP: 76.4% \n",
    "model trained on 20 epochs\n",
    "\n",
    "## Task 4c)\n",
    "We have implemented some modifications to improve the performance of the model. We have introduced batch normalization, which helps to normalize the input data and reduce overfitting. Additionally, we have used the Adam optimizer, which is a variant of gradient descent that adapts the learning rate to the parameters. These modifications have resulted in a slight increase in the precision of the model.\n",
    "\n",
    "Furthermore, we have experimented with different numbers of epochs and found that increasing the number of epochs by a small amount also improved the precision of the model. However, we have to be cautious in the choice of the number of epochs, as increasing the number too much can lead to overfitting, we increased the number of filters in some of the layers, which also contributed to the improvement in the model's precision.\n",
    "\n",
    "Finally, we have made a significant change by adjusting the minimum size of the first default box from [30, 30] to [15, 15] and [60, 60] to [30, 30]. This modification has resulted in a significant increase in the performance of the model. By decreasing the minimum size, we have increased the sensitivity of the model to smaller objects, which has led to a considerable improvement in the precision of the model for detecting small objects.\n",
    "\n",
    "Overall, our modifications have led to a substantial improvement in the performance of the SSD model. The use of batch normalization and Adam optimizer, along with the right choice of minimum size of the default box, has resulted in a highly accurate model for object detection.\n",
    "This is the \n",
    "![4c](4c.png)\n",
    "![4c loss](4c%20loss.png)\n",
    "\n",
    "\n",
    "## Task 4d)\n",
    "\n",
    "\n",
    "\n",
    "## Task 4e)\n",
    " \n",
    "![0](SSD/demo/mnist_output/0.png) ![10](SSD/demo/mnist_output/10.png)\n",
    "\n",
    "![11](SSD/demo/mnist_output/11.png) ![12](SSD/demo/mnist_output/12.png)\n",
    "\n",
    "![13](SSD/demo/mnist_output/13.png) ![14](SSD/demo/mnist_output/14.png)\n",
    "\n",
    "![1](SSD/demo/mnist_output/1.png) ![2](SSD/demo/mnist_output/2.png)\n",
    "\n",
    "![3](SSD/demo/mnist_output/3.png) ![4](SSD/demo/mnist_output/4.png)\n",
    "\n",
    "![5](SSD/demo/mnist_output/5.png) ![6](SSD/demo/mnist_output/6.png)\n",
    "\n",
    "![7](SSD/demo/mnist_output/7.png) ![8](SSD/demo/mnist_output/8.png)\n",
    "\n",
    "![9](SSD/demo/mnist_output/9.png)\n",
    "\n",
    "\n",
    "The model can't identify from the hole test some 4, 1 and 7. This number are quite obvious to identify but the model strugle to identify it.\n",
    "\n",
    "## Task 4f)\n",
    "FILL IN ANSWER. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
